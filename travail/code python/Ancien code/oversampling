from tpot import TPOTClassifier
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from sklearn.datasets import fetch_lfw_people
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import SVC
from sklearn.utils.fixes import loguniform
from sklearn.pipeline import make_pipeline
from imblearn.over_sampling import RandomOverSampler
from sklearn.utils.fixes import loguniform
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from imblearn.pipeline import Pipeline
 
BDD = pd.read_excel(
    'C:/Users/orkad/Desktop/stage emmanuel/Datasets-20220517T100241Z-001/Datasets/2-data_ossements/2-2 custom/feature_table_mzwid_0.019_minfrac_0_no_int.xlsx')
BDD2 = BDD
del BDD2['label']
y = BDD2['feature']
X = BDD2.drop('feature', axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25, stratify=y)

# =============================================================================
# pipeline
# =============================================================================


smt = SMOTE(random_state=42)
gau = GaussianNB()
pipeline = Pipeline(steps=[('ros', ros), ('gau', gau)])
pipeline.fit(X_train, y_train) 
y_hat = pipeline.predict(X_test)
print(classification_report(y_test, y_hat))
print(pipeline.named_steps)

# =============================================================================
# 
# =============================================================================
from collections import Counter
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split as tts
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier as KNN
from sklearn.metrics import classification_report
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline 
X, y = make_classification(n_classes=2, class_sep=2,
weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,
n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)
print(f'Original dataset shape {Counter(y)}')
pca = PCA()
smt = SMOTE(random_state=42)
knn = KNN()
pipeline = Pipeline([ ('pca', pca), ('knn', knn)])
X_train, X_test, y_train, y_test = tts(X, y, random_state=42)
pipeline.fit(X_train, y_train) 
y_hat = pipeline.predict(X_test)
print(classification_report(y_test, y_hat))

# =============================================================================
# 
# =============================================================================


smt = SMOTE(random_state=2, k_neighbors=1)
gau = GaussianNB()
pipeline = Pipeline(steps=[ ('ros', smt),('gau', gau)])
pipeline.fit(X_train, y_train) 
y_hat = pipeline.predict(X_test)
print(classification_report(y_test, y_hat))
print(pipeline.named_steps)